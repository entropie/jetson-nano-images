version: "3.8"

services:
  qwen2:
    build:
      context: .
      dockerfile: Dockerfile
    image: qwen2-gguf-server:latest
    container_name: qwen2
    ports:
      - "8092:8080"
    volumes:
      - /data:/data
    environment:
      HF_TOKEN: ${HF_TOKEN:?set HF_TOKEN in your .env}
      MODEL_REPO: bartowski/Qwen2-VL-2B-Instruct-GGUF
      MODEL_FILE: Qwen2-VL-2B-Instruct-Q4_K_M.gguf
      MMPROJ_FILE: mmproj-Qwen2-VL-2B-Instruct-f16.gguf
      HOST: 0.0.0.0
      PORT: "8080"
      CTX: "1024"
      NGL: "999"
      THREADS: "6"
      GGML_CUDA_FORCE_CUBLAS: "1"
      GGML_CUDA_DISABLE_GRAPHS: "1"
    devices:
      - "nvidia.com/gpu=all"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8080/v1/models >/dev/null || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
